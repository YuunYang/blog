---
title:  "【译】深度学习前言"
categories:
  - machine learning
tags: 
  - machine learning
  - deep learning
entries_layout: grid
lang_change: true
lang: cn
author_profile: true
toc: true
toc_label: "深度学习前言"
toc_sticky: true
hidden: false
---

开始阅读Ian Goodfellow、Yoshua Bengio、Aaron Courville三位大佬写的[`deep learning book`][deep learning]，这次不能烂尾了，决定每天花3-4个小时阅读英文原版，再用周末的时间把看过的部分理解并翻译一下，争取12月份之前完成整本书。

考虑到整本书文本量巨大。不会全文翻译。

## 前言

一直以来科学家和发明家都在寻求能够思考的机器，从古希腊一直到近现代计算机的发明。而今天artificial intelligence (AI)正在蓬勃发展，在很多应用领域和研究中都比较活跃。

### 什么是深度学习

对于人工智能来说，它适合解决那些能被正式的数学规则所描述的问题，而对于人类来说能很简单的通过直觉来解决的问题对于计算机来说却很困难，所以，这本书旨在解决这类问题；而解决这类问题的方法便是让计算机试着从经验中学习并从概念的层次理解这个世界，`每一个概念又是其与简单概念的关系所定义的`，也就意味着，它不需要人类一次性指定把所有所需的知识，概念层次结构允许它可以从简单的概念来建立和学习一套复杂的概念。如果我们把这些概念用图来表示的话，我们会发现这个图很深，有很多的图层。正式因为这样，我们会把这种方式成为`AI深度学习`

### 什么时候我们使用AI

很多成功的AI案例都发生在相对贫瘠和正规的环境下，并不需要计算机对这个世界有太多的了解；像 IBM 的 Deep Blue chess-playing system 在1997年打败了世界冠军，而对于象棋来说，他是有规可循的，而且可以通过简洁而正式的规则完全描述，所以建立起这样一个AI系统，对于程序员来讲是很容易的。

>这也就是说，对于我们来说，那些抽象的正式的任务我们很难去理解，而对于计算机来说却很容易

AI可以很容易击败世界象棋选手，却在识别物体、语音这些人类很容易完成的事情上举步维艰。人类一天的生活需要大量关于这个世界的知识，而其中很大一部分是我们我们的主观意识和直接，很难用正式的方式来表达。计算机同样需要这些知识，人工智能的一大挑战也是如何将这些非正式的知识应用到计算机。

因为如此，这时诞生了一种称之为基于知识的人工智能方法，将需要的知识硬编码，这样，计算机可以使用逻辑推理规则自动推理这些正式语言中的语句，但这样做会很死板，比如一个著名的项目`Cyc`便因为小说中`FredWhileShaving`而将小说人物Fred错认为电气而不是人。解决这个问题就需要AI系统自己通过原始数据去获取他们想要的知识，这种能力我们往往称之为`机器学习`。很多时候机器学习的算法很依赖我们给出的数据。如果我们给出的数据是有序正式的，算法速度往往能有指数级别的提升。

许多人工智能任务可以通过设计合适的模型来提取任务，然后将这些特性提供给一个简单的机器学习算法来解决，但很多时候我们其实很难知道到底使用哪一种特征值，这又回到前面了，我们主观或直觉上觉得很好去理解的事物，往往不适合作为特征值传给计算机。解决这个问题的一个方法是使用机器学习来发现从表示到输出的映射，以及表示本身。这种方法被称为`representation learning`。学习过的表示往往能够比手动设计的表示有更好的性能。它们还使人工智能系统能够快速适应新的任务，而无需人工干预。

当我们设计特征或学习特征的算法时，我们的目标常常是为了分离能够解释观察数据的`差别因子`；差别因子通常不是乘法组合的。这些因子通常不是能直接观察到的量，相反，它们可能是现实世界中观察不到的物体或者不可观测的力，但会影响可观测的量。他们还可能以概念的形式存在与人类的思考中，为观察数据提供有用的简化信息或推测原因。他们可以是被理解为让我们了解丰富多才的数据的一些概念或抽象。

### 为什么使用深度学习

现实生活中，人工智能的一大难点就是很多差别因子的同时影响我们能观察到的每一个数据。例如一张图片里红色的汽车的单点像素在黑夜里会和黑色很相近等等。许多应用需要我们清理差别因子并忽略我们所不关心的。当然，从原始的数据中提取出如此高层次、抽象的特征是非常难的，许多诸如说话口音这样的差别因子，只能通过对数据进行复杂的、接近人类水平的理解来辨识。当这几乎与获得原问题的表示一样困难是，乍一看，表示学习似乎并不能帮助我们。

这时候，**深度学习**通过其他较简单的表示来表达复杂表示，解决了表示学习的中心问题。深度学习让计算机通过简单的概念来建立复杂的概念。下图展示了一个深度学习系统如何通过组合更简单的概念来表示一个人的图像的概念，比如角和轮廓，这些概念反过来又用边来定义。深度学习模型的典型例子是前馈深度网络或多层感知机。 多层感知机仅仅是一个将一组输入值映射到输出值的数学函数。 该函数由许多较简单的函数复合而成。 我们可以认为不同数学函数的每一次应用都为输入提供了新的表示。

![1.2][1.2]上图深度学习模型的说明：计算机很难理解原始感官输入数据的含义，比如这张以像素值集合表示的图像。从一组像素到对象标识的函数映射非常复杂。如果直接处理，学习或评估这种映射几乎是不可能的。深度学习通过将所需的复杂映射分解为一系列嵌套的简单映射(每个映射由模型的不同层描述)来解决这一难题。输入显示在可见层，之所以这样命名是因为它包含我们能够观察到的变量。然后一系列隐藏的图层从图像中抽取越来越多的抽象特征。这些层被称为“隐藏”层，因为数据中没有提供它们的值;相反，模型必须确定哪些概念对解释观测数据中的关系有用。这里的图像是每个隐藏单元所代表的特征的可视化。给定像素，通过比较相邻像素的亮度，第一层可以很容易地识别边缘。给定第一个隐藏层对边缘的描述，第二个隐藏层可以很容易地搜索角和轮廓，这些都可以被识别为边缘集合。根据第二个隐藏层对图像的角和轮廓的描述，第三个隐藏层可以通过寻找特定的轮廓和角集合来检测特定对象的整个部分。最后，根据图像所包含的对象部分对图像的描述可用于识别图像中出现的对象（this description of the image in terms of the object parts it contains canbe used to recognize the objects present in the image）。转载自Zeiler和Fergus(2014)

深度大的网络可以按顺序执行更多的指令。顺序指令提供了强大的功能，因为后面的指令可以参考早期指令的结果。从这个角度看，并不是一个层的激活激活函数中的所有信息都必须编码解释输入的差别因子。表示还存储状态信息，来帮助程序理解输入。这种状态信息可以类似于传统计算机程序中的计数器或指针。它与输入的具体内容无关，但它帮助模型组织其处理过程。

## 深度学习历史趋势

通过历史背景了解深度学习是最简单的方法。与其提供详细的历史，这里仅仅提及深度学习的关键时期（长话短说）

- 深度学习有着深远而悠久的历史，不同哲学流派，他也有很过很多的名字，并且在流行程度方面也随之跌宕起伏。
- 随着训练量的不断增加，深度学习也变得更加有用
- 随着针对深度学习的计算机基础设施（软件和硬件）条件不断改善，深度学习模型的规模也在不断增大
- 深度学习解决的问题越来越多，精度也越来越高

### 神经网络的众多命名和多舛命运



[deep learning]: https://www.deeplearningbook.org/
[1.2]: /assets/images/2018-08-21-introduction-of-deep-learning/1.2.png