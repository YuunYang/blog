---
title:  "《机器学习》读书笔记"
categories:
  - machine learning
tags: 
  - 机器学习
  - 毕业设计
  - 周志华
entries_layout: grid
author_profile: true
toc: true
toc_label: "目录"
toc_sticky: true
---

周志华老师《机器学习》第一章绪论及第二章模型评估与选择

## 绪论

首先，了解机器学习是一门怎样的学科。

机器学习研究的主要内容，是关于在计算机上从数据中产生“模型”的算法，即“学习算法”，比如产生一个好瓜的模型。可以说机器学习是研究关于“学习算法”的学问。

### 基本术语
- 数据集（data set）：对所需研究的对象的数据的记录的集合；其中的每条记录是关于一件事物或对象的描述，称为一个“示例（instance）”或”样本（sample）“。
- 属性空间/样本空间/输入控件：属性张成的空间；如果把每一个属性作为坐标轴的一轴，则每一个示例都可以找到一个点与之对应；且由于每一个点都对应一个坐标向量，因此也把一个示例称为一个“特征向量（feature vector）”
- 训练数据（training data）：即训练过程中使用的数据，训练数据中的每一个样本称为”训练样本“，训练样本组成的集合称为”训练集“
- 分类（classification）：即欲预测的结果是离散的如预测西瓜到底是"好瓜"还是"坏瓜”
- 回归（regression）：预测的值为连续的值，如预测西瓜的成熟度是0.98还是0.37。可以分为“二分类”和“多分类”；预测任务是希望通过对训练集进行学习，建立一个从输入空间$$\chi$$到输出空间$$y$$的映射$$\text{f: }\chi]to\text{y}$$。与分类都属于“监督学习（supervised learning）”。
- 聚类（clustering）：即将训练集中的示例分成若干组，每组称为一个“簇（cluster）”；注意簇是自动形成的，其对应这一些潜在的概念。属于"无监督学习（unsupervised learning）"
- 泛化（generalization）：即簇划分能适用于没在训练集中出现的样本，学得模型适用与新样本的能力。
### 假设空间
首先介绍两个概念
- 归纳（induction）指从特殊到一般的泛化（generalization），即从具体的事实归结出一般性规律。
- 演绎（deduction）指从一般到特殊的特化（specialization），即从基础原理推演出具体状况。

对于归纳学习，最基本的是布尔概念学习，即是与不是。仅仅确定某一或几种特定的属性来表示是与否是远远不够的，因为我们在实际中往往会遇到之前没有遇到过的情况，也就是我们学习的目的是“泛化”；我们学习的过程就是在所有假设组成的空间中进行搜索的过程。
### 归纳偏好
归纳偏好就是指机器学习算法过程中对某种类型假设的偏好

为什么要有偏好？因为如果没有偏好，在每一次面临选择的时候，都进行随机选择，那么对于同一个模型，每次学习的结果都不一样，这样的学习是没有意义的。

“奥卡姆剃刀（occam’s razor）”是一种常用的，自然科学研究中最基本的用来引导算法确定正确性的原则。他的原则就是“若多个假设与观察一致选最简单的那个”。但哪一个是简单的却不是一个简单的问题。

另一个重要的概念是“没有免费的午餐定理（No Free Lunch Theorem）”；也就是在所有“问题”出现的机会相同或所有问题同等重要时，无论算法有多聪明，它们的期望始终是相同的。而实际情况是，我们关注的仅仅只是自己试图解决的问题，并不是关于这个问题的一个普世的答案，所以NFl定理的寓意即告诉我们，不能脱离具体问题，空泛讨论算法的合理性，因为如果考虑所有潜在的问题，则所有的学习算法都是一样的。我们应该关注学习算法的自身归纳偏好与问题是否相匹配。

## 模型评估与选择
